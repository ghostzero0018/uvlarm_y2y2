#!/usr/bin/python3

import rclpy
from rclpy.node import Node
from sensor_msgs.msg import Image
from std_msgs.msg import String, Float32
from cv_bridge import CvBridge
import pyrealsense2 as rs
import cv2
import numpy as np
import math
import signal
import time


# Realsense Node
class Realsense(Node):
    def __init__(self, fps=60):
        super().__init__('realsense')
        # Publishers
        self.image_publisher = self.create_publisher(Image, 'image', 10)
        self.detection_publisher = self.create_publisher(String, 'detection', 10)
        self.distancebottle_publisher = self.create_publisher(Float32, 'distancebottle', 10)
        self.x_publisher = self.create_publisher(Float32, 'x', 10)
        self.y_publisher = self.create_publisher(Float32, 'z', 10)

        # Initialize RealSense pipeline
        self.bridge = CvBridge()
        self.pipeline = rs.pipeline()
        self.colorizer = rs.colorizer()
        config = rs.config()
        pipeline_wrapper = rs.pipeline_wrapper(self.pipeline)
        pipeline_profile = config.resolve(pipeline_wrapper)
        device = pipeline_profile.get_device()

        # Check if RGB camera is available
        found_rgb = any(s.get_info(rs.camera_info.name) == 'RGB Camera' for s in device.sensors)
        if not found_rgb:
            print("Depth camera required!")
            exit(0)

        config.enable_stream(rs.stream.color, 848, 480, rs.format.bgr8, fps)
        config.enable_stream(rs.stream.depth, 848, 480, rs.format.z16, fps)

        # Align depth to color
        self.align_to = rs.stream.color
        self.align = rs.align(self.align_to)

        # Start streaming
        self.pipeline.start(config)
        self.isOk = True
        self.color_info = (0, 0, 255)

        # Initialize attributes
        self.depth = 0.0
        self.distance = 0.0
        self.dx, self.dz = 0.0, 0.0

    def read_imgs(self):
        frames = self.pipeline.wait_for_frames()

        # Align color frame to depth frame
        aligned_frames = self.align.process(frames)
        depth_frame = aligned_frames.get_depth_frame()
        color_frame = aligned_frames.get_color_frame()

        if not depth_frame or not color_frame:
            return

        # Get images
        depth_image = np.asanyarray(depth_frame.get_data())
        self.color_image = np.asanyarray(color_frame.get_data())

        # Convert to HSV and apply mask
        hsv = cv2.cvtColor(self.color_image, cv2.COLOR_BGR2HSV)
        h, s, v = cv2.split(hsv)
        mask = ((50 < h) & (h < 85) & (s > 100) & (v > 50)).astype(np.uint8) * 255

        kernel = np.ones((3, 3), np.uint8)
        mask = cv2.erode(mask, kernel, iterations=1)
        mask = cv2.dilate(mask, kernel, iterations=1)
        mask = cv2.blur(mask, (7, 7))

        # Detect objects
        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        if contours:
            largest_contour = max(contours, key=cv2.contourArea)
            ((self.x, self.y), radius) = cv2.minEnclosingCircle(largest_contour)
            if radius > 30:
                self.draw_object(depth_frame, color_frame)

        # Display images
        cv2.imshow('RealSense', self.color_image)
        cv2.waitKey(1)

    def draw_object(self, depth_frame, color_frame):
        self.x, self.y = int(self.x), int(self.y)
        self.depth = depth_frame.get_distance(self.x, self.y)

        if self.depth > 0:  # Only calculate distance if valid depth is available
            intrinsics = color_frame.profile.as_video_stream_profile().intrinsics
            self.dx, dy, self.dz = rs.rs2_deproject_pixel_to_point(intrinsics, [self.x, self.y], self.depth)
            self.distance = math.sqrt(self.dx**2 + dy**2 + self.dz**2)

        # Draw object markers
        cv2.circle(self.color_image, (self.x, self.y), int(self.distance * 100), self.color_info, 2)
        cv2.putText(self.color_image, f"Object Detected: {self.distance:.2f}m", (self.x + 10, self.y - 10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, self.color_info, 2)

    def publish_imgs(self):
        # Publish processed image
        msg_image = self.bridge.cv2_to_imgmsg(self.color_image, "bgr8")
        self.image_publisher.publish(msg_image)

        # Publish detection status
        detection_msg = String()
        detection_msg.data = "bottle founded" if self.depth > 0 else "bottle unfounded"
        self.detection_publisher.publish(detection_msg)

        # Publish distance and coordinates
        self.distancebottle_publisher.publish(Float32(data=self.distance))
        self.x_publisher.publish(Float32(data=self.dx))
        self.y_publisher.publish(Float32(data=self.dz))

    def signalInteruption(self, signum, frame):
        print("\nCtrl-C pressed")
        self.isOk = False


def process_img(args=None):
    rclpy.init(args=args)
    rsNode = Realsense()
    signal.signal(signal.SIGINT, rsNode.signalInteruption)

    while rsNode.isOk:
        rsNode.read_imgs()
        rsNode.publish_imgs()
        rclpy.spin_once(rsNode, timeout_sec=0.001)

    # Clean shutdown
    rsNode.pipeline.stop()
    rsNode.destroy_node()
    rclpy.shutdown()


if __name__ == '__main__':
    process_img()


