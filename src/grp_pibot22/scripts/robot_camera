#!/usr/bin/env python3

import pyrealsense2 as rs
import signal, time, numpy as np
import sys, cv2, rclpy
from rclpy.node import Node
import time
import math
import sys
from sensor_msgs.msg import Image
from cv_bridge import CvBridge
from rclpy.signals import SignalHandlerOptions

# Global flag for interrupt handling
isOk = True # Flag to indicate if the main loop should continue running

def signalInteruption(signum, frame): # Signal handler for interrupt signal (Ctrl-C)
    global isOk # Access the global flag variable
    print("\nCtrl-c pressed") # Print a message indicating the signal
    isOk = False # Set the flag to False to stop the main loop

signal.signal(signal.SIGINT, signalInteruption) # Register the signal handler for interrupt signal

# Node processes:
def main(): # Main function for the node
    global isOk # Access the global flag variable
    
    # Initialize ROS Node connected to the camera
    rclpy.init( signal_handler_options= SignalHandlerOptions.NO ) # Initialize the ROS client library
    rosNode = Node("RealSense_driver") # Create a ROS node
    camera = Realsense() # Create an instance of the Realsense class
    camera.initializeROSnode(rosNode) # Initialize the ROS node for the camera

    while isOk and rclpy.ok(): # Main loop to read and publish images
        camera.read_imgs() # Read images from the camera
        camera.publish_imgs() # Publish the images as ROS messages
        rclpy.spin_once(rosNode, timeout_sec=0.001) 

    try: # Disconnect the camera and shutdown the ROS node
        camera.disconnect() # Disconnect the camera
    except Exception as ex: # Handle any exceptions that occur
        print(f"Failed to disconnect camera: {ex}") # Print an error message
    try: # Shutdown the ROS node and the ROS client library
        rosNode.destroy_node() # Destroy the ROS node
    except Exception as ex: # Handle any exceptions that occur
        print(f"Failed to destory rosNode: {ex}") # Print an error message
    try: # Shutdown the ROS client library
        rclpy.shutdown() # Shutdown the ROS client library
    except Exception as ex: # Handle any exceptions that occur
        print(f"Failed to shutdown : {ex}") # Print an error message
    
# Realsense Node:
class Realsense(): # Create a class for the Realsense camera
    def __init__(self, fps= 60): 
        # Initialize attributes
        # Connect the camera
        
        # Configure depth and color streams
        self.pipeline = rs.pipeline() # Create a pipeline object for managing the camera streams
        self.config = rs.config() # Create a configuration object for the camera
        
        # Get device product line for setting a supporting resolution
        self.pipeline_wrapper = rs.pipeline_wrapper(self.pipeline) # Create a pipeline wrapper object for the pipeline
        self.pipeline_profile = self.config.resolve(self.pipeline_wrapper) # Resolve the pipeline profile
        self.device = self.pipeline_profile.get_device() # Get the device object from the pipeline profile
        self.device_product_line = str(self.device.get_info(rs.camera_info.product_line)) # Get the product line of the camera
        
        print( f"Connect: {self.device_product_line}" ) # Print the product line of the camera
        self.found_rgb = True # Flag to indicate if an RGB camera is found
        for s in self.device.sensors: # Loop over the sensors of the camera
            print( "Name:" + s.get_info(rs.camera_info.name) ) # Print the name of the sensor
            if s.get_info(rs.camera_info.name) == 'RGB Camera': # If the sensor is an RGB camera
                self.found_rgb = True # Set the flag to True

        if not (self.found_rgb): # If an RGB camera is not found
            print("Depth camera is equired ") # Print a message indicating that a depth camera is required
            exit(0) # Exit the program

        self.config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30) # Configure the color stream
        self.config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30) # Configure the depth stream
        
        # Start streaming
        self.pipeline.start(self.config) # Start the camera stream
        
    def initializeROSnode(self, ros_node): # Initialize the ROS node for the camera
        # Initialize publishers
        self.image_publisher = ros_node.create_publisher(Image, 'sensor_msgs/image', 10) # Create a publisher for the color image
        self.depth_publisher = ros_node.create_publisher(Image, 'sensor_msgs/depth', 10) # Create a publisher for the depth image
        self.ros_node = ros_node

    def read_imgs(self): 
        # Read data from camera

        sys.stdout.write("-")
        # Wait for a coherent tuple of frames: depth, color and accel
        self.frames = self.pipeline.wait_for_frames() # Wait for a coherent set of frames
        self.color_frame = self.frames.first(rs.stream.color) # Get the color frame
        self.depth_frame = self.frames.first(rs.stream.depth) # Get the depth frame
        
        # Convert images to numpy arrays
        self.depth_image = np.asanyarray(self.depth_frame.get_data()) # Convert the depth frame to a numpy array
        self.color_image = np.asanyarray(self.color_frame.get_data()) # Convert the color frame to a numpy array
        # Apply colormap on depth image (image must be converted to 8-bit per pixel first)
        self.depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(self.depth_image, alpha=0.03), cv2.COLORMAP_JET) # Apply a colormap to the depth image
        self.depth_colormap_dim = self.depth_colormap.shape # Get the dimensions of the depth colormap
        self.color_colormap_dim = self.color_image.shape # Get the dimensions of the color image
                
    def publish_imgs(self): # Publish the images as ROS messages
        if not self.ros_node or not rclpy.ok(): # Check if the ROS node is valid and the context is valid
            self.ros_node.get_logger().error("ROS Node is not valid or context is invalid. Cannot publish messages.") # Log an error message
            return # Exit the function

        try: # Publish the images
            self.bridge = CvBridge() # Create a CvBridge object for converting images

            msg_image = self.bridge.cv2_to_imgmsg(self.color_image, "bgr8") # Convert the color image to a ROS image message
            msg_image.header.stamp = self.ros_node.get_clock().now().to_msg() # Set the timestamp of the message
            msg_image.header.frame_id = "image" # Set the frame ID of the message
            self.image_publisher.publish(msg_image) # Publish the message

            msg_depth = self.bridge.cv2_to_imgmsg(self.depth_colormap, "bgr8") # Convert the depth image to a ROS image message
            msg_depth.header.stamp = msg_image.header.stamp # Set the timestamp of the message
            msg_depth.header.frame_id = "depth" # Set the frame ID of the message
            self.depth_publisher.publish(msg_depth) # Publish the message
            self.ros_node.get_logger().error("Published.") # Log a message indicating successful publication
            
        except Exception as ex: 
            self.ros_node.get_logger().error(f"Failed to publish images: {ex}") # Log an error message


    def disconnect(self): # disconnect the camera, free the resource.
        
        # Stop streaming
        print("\nEnding camera...") # Print a message indicating the end of the camera stream
        self.pipeline.stop() # Stop the camera stream

# Script trigger
if __name__ == '__main__':
    main()