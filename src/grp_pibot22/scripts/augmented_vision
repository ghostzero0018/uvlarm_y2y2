import cv2 as cv
import numpy as np
import pyrealsense2 as rs  # Import the RealSense library
import math

# Initialize the RealSense pipeline
pipeline = rs.pipeline()
config = rs.config()
colorizer = rs.colorizer()

# Configure the pipeline to stream at 30 frames per second
config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30) # Enable the depth stream
config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30) # Enable the color stream
pipeline.start(config) # Start the pipeline

align_to = rs.stream.depth # Align color frame to depth frame
align = rs.align(align_to) # Create alignment object

# Set up for drawing and template matching
color_info = (0, 0, 255)  # Red color in BGR
rayon = 10  # Radius for circles to be drawn

# Load template for object detection
img_rgb_template = cv.imread('car.png')  # Check if 'car.png' is the correct file or if it should be 'template.png'
img_gray_template = cv.cvtColor(img_rgb_template, cv.COLOR_BGR2GRAY) # Convert to grayscale
template = cv.imread('template.png', 0) # Load the template image
w, h = template.shape[::-1] # Get the width and height of the template image
threshold_template = 0.3  # Threshold for accepting a match

# Define HSV color range for segmentation
color = 60  # Hue value could be adjusted
lo = np.array([color - 15, 50, 50])  # Lower bound of HSV
hi = np.array([color + 15, 255, 255])  # Upper bound of HSV

# Variables for object detection logic
object_detected = False
distance_threshold = 1.0  # Distance threshold in meters

# Morphological operations kernel
kernel = np.ones((3, 3), np.uint8)

try:
    while True:
        # Get frames from the camera
        frames = pipeline.wait_for_frames() # Wait for the next set of frames from the camera
        aligned_frames = align.process(frames) # Align the frames
        depth_frame = aligned_frames.get_depth_frame() # Get the aligned depth frame
        aligned_color_frame = aligned_frames.get_color_frame() # Get the aligned color frame

        if not depth_frame or not aligned_color_frame: # Check if frames are available
            continue  # Skip the loop iteration if frames are not available

        # Create a colorized depth map
        colorized_depth = colorizer.colorize(depth_frame) # Colorize the depth frame
        depth_colormap = np.asanyarray(colorized_depth.get_data()) # Convert the colorized depth frame to a numpy array

        # Zero depth should be treated as no data and set to black
        depth_colormap[depth_colormap == 0] = 0 # Set zero depth values to black

        # Get intrinsic parameters of the color frame for depth calculation
        color_intrin = aligned_color_frame.profile.as_video_stream_profile().intrinsics # Get the intrinsic parameters of the color frame
        color_image = np.asanyarray(aligned_color_frame.get_data()) # Convert the color frame to a numpy array

        # Calculate the center pixel's depth and convert to 3D space
        x, y = int(color_image.shape[1] / 2), int(color_image.shape[0] / 2) # Get the center pixel coordinates
        depth = depth_frame.get_distance(x, y) # Get the depth value at the center pixel
        dx, dy, dz = rs.rs2_deproject_pixel_to_point(color_intrin, [x, y], depth) # Deproject the center pixel to 3D space
        distance = math.sqrt(dx ** 2 + dy ** 2 + dz ** 2) # Calculate the distance from the camera

        # Detect objects within a specified distance
        if distance < distance_threshold: # Check if the distance is within the threshold
            hsv_image = cv.cvtColor(color_image, cv.COLOR_BGR2HSV) # Convert the BGR image to an HSV image
            mask = cv.inRange(hsv_image, lo, hi) # Create a mask for the green color in the HSV image
            mask = cv.erode(mask, kernel, iterations=1) # Erode the mask to remove noise
            mask = cv.dilate(mask, kernel, iterations=1) # Dilate the mask to fill gaps
            image_segmented = cv.bitwise_and(color_image, color_image, mask=mask) # Apply the mask to the color image

            # Perform template matching
            img_gray_segmented = cv.cvtColor(image_segmented, cv.COLOR_BGR2GRAY) # Convert the segmented image to grayscale
            res = cv.matchTemplate(img_gray_segmented, template, cv.TM_CCOEFF_NORMED) # Perform template matching
            loc = np.where(res >= threshold_template) # Find the locations where the template matches

            object_detected = False # Reset object detection flag
            for pt in zip(*loc[::-1]): # Iterate over the locations
                cv.rectangle(color_image, pt, (pt[0] + w, pt[1] + h), color_info, 2) # Draw a rectangle around the detected object
                object_detected = True # Set object detection flag to True

            # Display the result
            images = np.hstack((color_image, depth_colormap, image_segmented)) 
            cv.circle(images, (int(x), int(y)), int(rayon), color_info, 2) # Draw a circle at the center pixel
            cv.putText(images, "D=" + str(round(distance, 2)), (int(x) + 10, int(y) - 10), 
                       cv.FONT_HERSHEY_DUPLEX, 1, color_info, 1, cv.LINE_AA) # Display distance
            cv.imshow('RealSense', images) # Display the images
            cv.waitKey(1) # Wait for a short time to allow the images to be displayed

            if object_detected: # Check if an object is detected
                print("Object_detected!") # Print a message indicating object detection
            else: # If no object is detected
                print("Object_not_detected.") # Print a message indicating no object detection

except Exception as ex: # Handle exceptions
    print(ex) # Print the exception message

finally:
    # Stop the pipeline when done
    pipeline.stop() # Stop the RealSense pipeline
